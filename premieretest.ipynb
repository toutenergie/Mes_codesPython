{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\,'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\,'\n",
      "C:\\Users\\Abdoulaye_Faye\\AppData\\Local\\Temp\\ipykernel_1248\\1758998141.py:1: SyntaxWarning: invalid escape sequence '\\,'\n",
      "  dataset = pd.read_csv(\"TitanicDataset.csv\",sep='\\,')\n",
      "C:\\Users\\Abdoulaye_Faye\\AppData\\Local\\Temp\\ipykernel_1248\\1758998141.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dataset = pd.read_csv(\"TitanicDataset.csv\",sep='\\,')\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"TitanicDataset.csv\",sep='\\,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\"1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>\"\"Braund</td>\n",
       "      <td>Mr. Owen Harris\"\"</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"Cumings</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer)\"\"</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>\"\"Heikkinen</td>\n",
       "      <td>Miss. Laina\"\"</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"Futrelle</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel)\"\"</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>\"\"Allen</td>\n",
       "      <td>Mr. William Henry\"\"</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived       Pclass  \\\n",
       "\"1            0         3     \"\"Braund   \n",
       "\"2            1         1    \"\"Cumings   \n",
       "\"3            1         3  \"\"Heikkinen   \n",
       "\"4            1         1   \"\"Futrelle   \n",
       "\"5            0         3      \"\"Allen   \n",
       "\n",
       "                                             Name     Sex   Age  SibSp  Parch  \\\n",
       "\"1                              Mr. Owen Harris\"\"    male  22.0      1      0   \n",
       "\"2   Mrs. John Bradley (Florence Briggs Thayer)\"\"  female  38.0      1      0   \n",
       "\"3                                  Miss. Laina\"\"  female  26.0      0      0   \n",
       "\"4           Mrs. Jacques Heath (Lily May Peel)\"\"  female  35.0      1      0   \n",
       "\"5                            Mr. William Henry\"\"    male  35.0      0      0   \n",
       "\n",
       "              Ticket     Fare Cabin Embarked  \n",
       "\"1         A/5 21171   7.2500   NaN       S\"  \n",
       "\"2          PC 17599  71.2833   C85       C\"  \n",
       "\"3  STON/O2. 3101282   7.9250   NaN       S\"  \n",
       "\"4            113803  53.1000  C123       S\"  \n",
       "\"5            373450   8.0500   NaN       S\"  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraitemant de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection des colonnes pertinants pour notre problematique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\"1</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\"Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"2</th>\n",
       "      <td>1</td>\n",
       "      <td>\"\"Cumings</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\"Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"4</th>\n",
       "      <td>1</td>\n",
       "      <td>\"\"Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"5</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\"Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived       Pclass     Sex   Age\n",
       "\"1         3     \"\"Braund    male  22.0\n",
       "\"2         1    \"\"Cumings  female  38.0\n",
       "\"3         3  \"\"Heikkinen  female  26.0\n",
       "\"4         1   \"\"Futrelle  female  35.0\n",
       "\"5         3      \"\"Allen    male  35.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=dataset[['Survived', 'Pclass', 'Sex', 'Age']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre de valeurs NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Sex           0\n",
       "Age         177\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre de valeurs manquentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Sex           0\n",
       "Age         177\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netoyage de la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetN  = dataset.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division de la base de données en deux base train et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\"1</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\"Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"2</th>\n",
       "      <td>1</td>\n",
       "      <td>\"\"Cumings</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\"Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"4</th>\n",
       "      <td>1</td>\n",
       "      <td>\"\"Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"5</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\"Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"886</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\"Rice</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"887</th>\n",
       "      <td>2</td>\n",
       "      <td>\"\"Montvila</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"888</th>\n",
       "      <td>1</td>\n",
       "      <td>\"\"Graham</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"890</th>\n",
       "      <td>1</td>\n",
       "      <td>\"\"Behr</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"891</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\"Dooley</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Survived       Pclass     Sex   Age\n",
       "\"1           3     \"\"Braund    male  22.0\n",
       "\"2           1    \"\"Cumings  female  38.0\n",
       "\"3           3  \"\"Heikkinen  female  26.0\n",
       "\"4           1   \"\"Futrelle  female  35.0\n",
       "\"5           3      \"\"Allen    male  35.0\n",
       "...        ...          ...     ...   ...\n",
       "\"886         3       \"\"Rice  female  39.0\n",
       "\"887         2   \"\"Montvila    male  27.0\n",
       "\"888         1     \"\"Graham  female  19.0\n",
       "\"890         1       \"\"Behr    male  26.0\n",
       "\"891         3     \"\"Dooley    male  32.0\n",
       "\n",
       "[714 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\"\"Braund', '\"\"Cumings', '\"\"Heikkinen', '\"\"Futrelle', '\"\"Allen',\n",
       "       '\"\"McCarthy', '\"\"Palsson', '\"\"Johnson', '\"\"Nasser', '\"\"Sandstrom',\n",
       "       '\"\"Bonnell', '\"\"Saundercock', '\"\"Andersson', '\"\"Vestrom',\n",
       "       '\"\"Hewlett', '\"\"Rice', '\"\"Vander Planke', '\"\"Fynney', '\"\"Beesley',\n",
       "       '\"\"McGowan', '\"\"Sloper', '\"\"Asplund', '\"\"Fortune', '\"\"Uruchurtu',\n",
       "       '\"\"Wheadon', '\"\"Meyer', '\"\"Holverson', '\"\"Cann', '\"\"Nicola-Yarred',\n",
       "       '\"\"Ahlin', '\"\"Turpin', '\"\"Laroche', '\"\"Devaney',\n",
       "       '\"\"Arnold-Franchi', '\"\"Panula', '\"\"Nosworthy', '\"\"Harper',\n",
       "       '\"\"Faunthorpe', '\"\"Ostby', '\"\"Rugg', '\"\"Novel', '\"\"West',\n",
       "       '\"\"Goodwin', '\"\"Sirayanian', '\"\"Icard', '\"\"Harris', '\"\"Skoog',\n",
       "       '\"\"Nye', '\"\"Crease', '\"\"Kink', '\"\"Jenkin', '\"\"Hood',\n",
       "       '\"\"Chronopoulos', '\"\"Bing', '\"\"Moen', '\"\"Caldwell', '\"\"Dowdell',\n",
       "       '\"\"Waelens', '\"\"Sheerlinck', '\"\"Carrau', '\"\"Ilett', '\"\"Backstrom',\n",
       "       '\"\"Ford', '\"\"Celotti', '\"\"Christmann', '\"\"Andreasson', '\"\"Chaffee',\n",
       "       '\"\"Dean', '\"\"Coxon', '\"\"Goldschmidt', '\"\"Greenfield', '\"\"Doling',\n",
       "       '\"\"Kantor', '\"\"Petranec', '\"\"White', '\"\"Johansson', '\"\"Gustafsson',\n",
       "       '\"\"Mionoff', '\"\"Salkjelsvik', '\"\"Rekic', '\"\"Porter', '\"\"Zabour',\n",
       "       '\"\"Barton', '\"\"Jussila', '\"\"Attalah', '\"\"Pekoniemi', '\"\"Connors',\n",
       "       '\"\"Baxter', '\"\"Hickman', '\"\"Webber', '\"\"Madsen', '\"\"Ekstrom',\n",
       "       '\"\"Drazenoic', '\"\"Coelho', '\"\"Robins', '\"\"Weisz', '\"\"Sobey',\n",
       "       '\"\"Richard', '\"\"Newsom', '\"\"Osen', '\"\"Giglio', '\"\"Nysten',\n",
       "       '\"\"Hakkarainen', '\"\"Burke', '\"\"Andrew', '\"\"Nicholls', '\"\"Navratil',\n",
       "       '\"\"Byles', '\"\"Bateman', '\"\"Pears', '\"\"Meo', '\"\"van Billiard',\n",
       "       '\"\"Williams', '\"\"Gilnagh', '\"\"Corn', '\"\"Cribb', '\"\"Watt',\n",
       "       '\"\"Bengtsson', '\"\"Calic', '\"\"Goldsmith', '\"\"Ling',\n",
       "       '\"\"Van der hoef', '\"\"Sivola', '\"\"Smith', '\"\"Klasen', '\"\"Isham',\n",
       "       '\"\"Hale', '\"\"Leonard', '\"\"Becker', '\"\"Kink-Heilmann', '\"\"Romaine',\n",
       "       '\"\"Bourke', '\"\"Turcin', '\"\"Pinsky', '\"\"Carbines',\n",
       "       '\"\"Andersen-Jensen', '\"\"Brown', '\"\"Lurette', '\"\"Olsen', '\"\"Yrois',\n",
       "       '\"\"Vande Walle', '\"\"Johanson', '\"\"Youseff', '\"\"Cohen', '\"\"Strom',\n",
       "       '\"\"Albimona', '\"\"Carr', '\"\"Blank', '\"\"Ali', '\"\"Cameron',\n",
       "       '\"\"Perkin', '\"\"Givard', '\"\"Newell', '\"\"Honkanen', '\"\"Jacobsohn',\n",
       "       '\"\"Bazzani', '\"\"Sunderland', '\"\"Bracken', '\"\"Green', '\"\"Hoyt',\n",
       "       '\"\"Berglund', '\"\"Mellors', '\"\"Lovell', '\"\"Fahlstrom', '\"\"Larsson',\n",
       "       '\"\"Sjostedt', '\"\"Leyson', '\"\"Hold', '\"\"Collyer', '\"\"Pengelly',\n",
       "       '\"\"Hunt', '\"\"Coleridge', '\"\"Maenpaa', '\"\"Minahan', '\"\"Lindahl',\n",
       "       '\"\"Hamalainen', '\"\"Beckwith', '\"\"Carter', '\"\"Stead', '\"\"Lobb',\n",
       "       '\"\"Rosblom', '\"\"Touma', '\"\"Cherry', '\"\"Ward', '\"\"Parrish',\n",
       "       '\"\"Taussig', '\"\"Harrison', '\"\"Reeves', '\"\"Persson', '\"\"Graham',\n",
       "       '\"\"Bissette', '\"\"Tornquist', '\"\"Mellinger', '\"\"Natsch',\n",
       "       '\"\"Andrews', '\"\"Lindblom', '\"\"Abbott', '\"\"Duane', '\"\"Olsson',\n",
       "       '\"\"de Pelsmaeker', '\"\"Dorking', '\"\"Stankovic', '\"\"de Mulder',\n",
       "       '\"\"Naidenoff', '\"\"Hosono', '\"\"Connolly', '\"\"Barber', '\"\"Bishop',\n",
       "       '\"\"Levy', '\"\"Haas', '\"\"Mineff', '\"\"Hanna', '\"\"Allison',\n",
       "       '\"\"Penasco y Castellana', '\"\"Abelson', '\"\"Francatelli', '\"\"Hays',\n",
       "       '\"\"Ryerson', '\"\"Lahtinen', '\"\"Hendekovic', '\"\"Hart', '\"\"Nilsson',\n",
       "       '\"\"Moraweck', '\"\"Wick', '\"\"Spedden', '\"\"Dennis', '\"\"Danoff',\n",
       "       '\"\"Slayter', '\"\"Young', '\"\"Nysveen', '\"\"Ball', '\"\"Hippach',\n",
       "       '\"\"Partner', '\"\"Burns', '\"\"Dahl', '\"\"Blackwell', '\"\"Collander',\n",
       "       '\"\"Sedgwick', '\"\"Fox', '\"\"Coutts', '\"\"Dimic', '\"\"Odahl', '\"\"Elias',\n",
       "       '\"\"Vanden Steen', '\"\"Bowerman', '\"\"Funk', '\"\"del Carlo',\n",
       "       '\"\"Barbara', '\"\"Asim', '\"\"Adahl', '\"\"Warren', '\"\"Aubart',\n",
       "       '\"\"Harder', '\"\"Wiklund', '\"\"Beavan', '\"\"Ringhini', '\"\"Landergren',\n",
       "       '\"\"Widener', '\"\"Betros', '\"\"Bidois', '\"\"Nakid', '\"\"Tikkanen',\n",
       "       '\"\"Davies', '\"\"Buss', '\"\"Lehmann', '\"\"Jansson', '\"\"McKane',\n",
       "       '\"\"Pain', '\"\"Trout', '\"\"Niskanen', '\"\"Adams', '\"\"Oreskovic',\n",
       "       '\"\"Gale', '\"\"Widegren', '\"\"Richards', '\"\"Birkeland', '\"\"Sundman',\n",
       "       '\"\"Drew', '\"\"Silven', '\"\"Matthews', '\"\"Van Impe', '\"\"Charters',\n",
       "       '\"\"Zimmerman', '\"\"Danbom', '\"\"Clarke', '\"\"Phillips', '\"\"Pickard',\n",
       "       '\"\"Bjornstrom-Steffansson', '\"\"Louch', '\"\"Kallio', '\"\"Silvey',\n",
       "       '\"\"Kvillner', '\"\"Hampe', '\"\"Petterson', '\"\"Reynaldo', '\"\"Dodge',\n",
       "       '\"\"Seward', '\"\"Baclini', '\"\"Peuchen', '\"\"Foreman', '\"\"Goldenberg',\n",
       "       '\"\"Jalsevac', '\"\"Millet', '\"\"Toomey', '\"\"Anderson', '\"\"Morley',\n",
       "       '\"\"Gee', '\"\"Milling', '\"\"Goncalves', '\"\"Smart', '\"\"Cacic',\n",
       "       '\"\"Jerwan', '\"\"Strandberg', '\"\"Renouf', '\"\"Karlsson', '\"\"Hirvonen',\n",
       "       '\"\"Rouse', '\"\"Turkula', '\"\"Kent', '\"\"Somerton', '\"\"Windelov',\n",
       "       '\"\"Molson', '\"\"Artagaveytia', '\"\"Stanley', '\"\"Eustis',\n",
       "       '\"\"Svensson', '\"\"Canavan', '\"\"Laitinen', '\"\"Maioni', '\"\"Quick',\n",
       "       '\"\"Lang', '\"\"Daly', '\"\"McGough', '\"\"Rothschild', '\"\"Coleff',\n",
       "       '\"\"Walker', '\"\"Lemore', '\"\"Angle', '\"\"Pavlovic', '\"\"Perreault',\n",
       "       '\"\"Vovk', '\"\"Farrell', '\"\"Ridsdale', '\"\"Salonen', '\"\"Hocking',\n",
       "       '\"\"Butt', '\"\"LeRoy', '\"\"Frolicher', '\"\"Crosby', '\"\"Beane',\n",
       "       '\"\"Douglas', '\"\"Nicholson', '\"\"Thayer', '\"\"Sharp', '\"\"Leeni',\n",
       "       '\"\"Ohman', '\"\"Wright', '\"\"Duff Gordon', '\"\"de Messemaeker',\n",
       "       '\"\"Sivic', '\"\"Norman', '\"\"Stoytcheff', '\"\"Jonsson', '\"\"Appleton',\n",
       "       '\"\"Flynn', '\"\"Rush', '\"\"Patchett', '\"\"Garside', '\"\"Christy',\n",
       "       '\"\"Downton', '\"\"Ross', '\"\"Jarvis', '\"\"Frolicher-Stehli',\n",
       "       '\"\"Gilinski', '\"\"Rintamaki', '\"\"Stephenson', '\"\"Elsbury',\n",
       "       '\"\"Chapman', '\"\"Torber', '\"\"Homer', '\"\"Lindell', '\"\"Karaic',\n",
       "       '\"\"Daniel', '\"\"Shutes', '\"\"Brocklebank', '\"\"Herman', '\"\"Gavey',\n",
       "       '\"\"Yasbeck', '\"\"Kimball', '\"\"Hansen', '\"\"Bowen', '\"\"Sutton',\n",
       "       '\"\"Kirkland', '\"\"Longley', '\"\"Bostandyeff', '\"\"Barkworth',\n",
       "       '\"\"Lundahl', '\"\"Stahelin-Maeglin', '\"\"Davis', '\"\"Leinonen',\n",
       "       '\"\"Jensen', '\"\"Sagesser', '\"\"Cor', '\"\"Simonius-Blumer', '\"\"Kalvik',\n",
       "       '\"\"Hegarty', '\"\"Eitemiller', '\"\"Frauenthal', '\"\"Badt', '\"\"Colley',\n",
       "       '\"\"Lindqvist', '\"\"Butler', '\"\"Cook', '\"\"Davidson', '\"\"Mitchell',\n",
       "       '\"\"Wilhelms', '\"\"Edvardsson', '\"\"Sawyer', '\"\"Turja', '\"\"Cardeza',\n",
       "       '\"\"Hassab', '\"\"Olsvigen', '\"\"Dakic', '\"\"Fischer', '\"\"Madill',\n",
       "       '\"\"Dick', '\"\"Karun', '\"\"Saad', '\"\"Weir', '\"\"Kelly', '\"\"Humblen',\n",
       "       '\"\"Astor', '\"\"Silverthorne', '\"\"Gallagher', '\"\"Calderhead',\n",
       "       '\"\"Cleaver', '\"\"Mayne', '\"\"Taylor', '\"\"Greenberg', '\"\"Soholt',\n",
       "       '\"\"Endres', '\"\"Troutt', '\"\"Gillespie', '\"\"Hodges', '\"\"Chambers',\n",
       "       '\"\"Bryhl', '\"\"Ilmakangas', '\"\"Hassan', '\"\"Berriman',\n",
       "       '\"\"Troupiansky', '\"\"Lesurer', '\"\"Cavendish', '\"\"McNamee',\n",
       "       '\"\"Stranden', '\"\"Sinkkonen', '\"\"Marvin', '\"\"Connaghton', '\"\"Wells',\n",
       "       '\"\"Moor', '\"\"Vande Velde', '\"\"Jonkoff', '\"\"Carlsson', '\"\"Bailey',\n",
       "       '\"\"Theobald', '\"\"Rothes', '\"\"Nirva', '\"\"Barah', '\"\"Eklund',\n",
       "       '\"\"Hogeboom', '\"\"Mangan', '\"\"Gronnestad', '\"\"Lievens', '\"\"Mack',\n",
       "       '\"\"Myhrman', '\"\"Emanuel', '\"\"Robert', '\"\"Ayoub', '\"\"Long',\n",
       "       '\"\"Harmer', '\"\"Sjoblom', '\"\"Guggenheim', '\"\"Gaskell',\n",
       "       '\"\"Dantcheff', '\"\"Otter', '\"\"Leader', '\"\"Osman',\n",
       "       '\"\"Ibrahim Shawah', '\"\"Ponesell', '\"\"Thomas', '\"\"Hedman',\n",
       "       '\"\"Pettersson', '\"\"Alexander', '\"\"Lester', '\"\"Slemen', '\"\"Tomlin',\n",
       "       '\"\"Heininen', '\"\"Mallet', '\"\"Holm', '\"\"Lulic', '\"\"Reuchlin',\n",
       "       '\"\"Stone', '\"\"Augustsson', '\"\"Allum', '\"\"Compton', '\"\"Pasic',\n",
       "       '\"\"Chip', '\"\"Alhomaki', '\"\"Mudd', '\"\"Serepeca', '\"\"Lemberopolous',\n",
       "       '\"\"Culumovic', '\"\"Abbing', '\"\"Markoff', '\"\"Boulos', '\"\"Lines',\n",
       "       '\"\"Aks', '\"\"Giles', '\"\"Swift', '\"\"Gill', '\"\"Bystrom',\n",
       "       '\"\"Duran y More', '\"\"Roebling', '\"\"Balkic', '\"\"Vander Cruyssen',\n",
       "       '\"\"Najib', '\"\"Petroff', '\"\"Potter', '\"\"Shelley', '\"\"Markun',\n",
       "       '\"\"Dahlberg', '\"\"Banfield', '\"\"Sutehall', '\"\"Montvila', '\"\"Behr',\n",
       "       '\"\"Dooley'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetN['Pclass'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toutenergie/Mes_codesPython/blob/main/Copie_de_recap_indexation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " %%capture\n",
        "!pip install -U langchain-community\n",
        "!pip install docling\n",
        "!pip install sympy==1.11.1\n",
        "!pip install sympy --upgrade"
      ],
      "metadata": {
        "id": "Uw8-FOjSQO6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElAioS4SYFFH",
        "outputId": "10926b47-008c-4c1b-a648-40df870eea83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: docling in /usr/local/lib/python3.10/dist-packages (2.8.3)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from docling) (4.12.3)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.10/dist-packages (from docling) (2024.8.30)\n",
            "Requirement already satisfied: deepsearch-glm<0.27.0,>=0.26.1 in /usr/local/lib/python3.10/dist-packages (from docling) (0.26.2)\n",
            "Requirement already satisfied: docling-core<3.0.0,>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from docling) (2.6.1)\n",
            "Requirement already satisfied: docling-ibm-models<3.0.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from docling) (2.0.7)\n",
            "Requirement already satisfied: docling-parse<3.0.0,>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from docling) (2.1.2)\n",
            "Requirement already satisfied: easyocr<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from docling) (1.7.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from docling) (1.2.0)\n",
            "Requirement already satisfied: huggingface_hub<1,>=0.23 in /usr/local/lib/python3.10/dist-packages (from docling) (0.26.2)\n",
            "Requirement already satisfied: lxml<6.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from docling) (5.3.0)\n",
            "Requirement already satisfied: marko<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from docling) (2.1.2)\n",
            "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.10/dist-packages (from docling) (3.1.5)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from docling) (2.2.2)\n",
            "Requirement already satisfied: pydantic<2.10,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from docling) (2.9.2)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from docling) (2.6.1)\n",
            "Requirement already satisfied: pypdfium2<5.0.0,>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from docling) (4.30.0)\n",
            "Requirement already satisfied: python-docx<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from docling) (1.1.2)\n",
            "Requirement already satisfied: python-pptx<2.0.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from docling) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.10/dist-packages (from docling) (2.32.3)\n",
            "Requirement already satisfied: rtree<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from docling) (1.3.0)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from docling) (1.13.1)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /usr/local/lib/python3.10/dist-packages (from docling) (0.12.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (2.6)\n",
            "Requirement already satisfied: docutils!=0.21 in /usr/local/lib/python3.10/dist-packages (from deepsearch-glm<0.27.0,>=0.26.1->docling) (0.21.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from deepsearch-glm<0.27.0,>=0.26.1->docling) (1.26.4)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from deepsearch-glm<0.27.0,>=0.26.1->docling) (1.0.1)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from deepsearch-glm<0.27.0,>=0.26.1->docling) (13.9.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from deepsearch-glm<0.27.0,>=0.26.1->docling) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from deepsearch-glm<0.27.0,>=0.26.1->docling) (4.66.6)\n",
            "Requirement already satisfied: jsonref<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from docling-core<3.0.0,>=2.6.1->docling) (1.1.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /usr/local/lib/python3.10/dist-packages (from docling-core<3.0.0,>=2.6.1->docling) (4.23.0)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from docling-core<3.0.0,>=2.6.1->docling) (10.4.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.1 in /usr/local/lib/python3.10/dist-packages (from docling-core<3.0.0,>=2.6.1->docling) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from docling-core<3.0.0,>=2.6.1->docling) (4.12.2)\n",
            "Requirement already satisfied: jsonlines<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from docling-ibm-models<3.0.0,>=2.0.6->docling) (3.1.0)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.6.0.66 in /usr/local/lib/python3.10/dist-packages (from docling-ibm-models<3.0.0,>=2.0.6->docling) (4.10.0.84)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from docling-ibm-models<3.0.0,>=2.0.6->docling) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision<1,>=0 in /usr/local/lib/python3.10/dist-packages (from docling-ibm-models<3.0.0,>=2.0.6->docling) (0.20.1+cu121)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr<2.0,>=1.7->docling) (0.24.0)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.10/dist-packages (from easyocr<2.0,>=1.7->docling) (0.6.3)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr<2.0,>=1.7->docling) (2.0.6)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from easyocr<2.0,>=1.7->docling) (1.3.0.post6)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from easyocr<2.0,>=1.7->docling) (1.11.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1,>=0.23->docling) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1,>=0.23->docling) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1,>=0.23->docling) (24.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl<4.0.0,>=3.1.5->docling) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10,>=2.0.0->docling) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10,>=2.0.0->docling) (2.23.4)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx<2.0.0,>=1.0.2->docling) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.32.3->docling) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.32.3->docling) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.32.3->docling) (2.2.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13.0,>=0.12.5->docling) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13.0,>=0.12.5->docling) (1.5.4)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines<4.0.0,>=3.1.0->docling-ibm-models<3.0.0,>=2.0.6->docling) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.6.1->docling) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.6.1->docling) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.6.1->docling) (0.21.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->docling) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->deepsearch-glm<0.27.0,>=0.26.1->docling) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.7.0->deepsearch-glm<0.27.0,>=0.26.1->docling) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<3.0.0,>=2.0.6->docling) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<3.0.0,>=2.0.6->docling) (3.1.4)\n",
            "Collecting sympy==1.13.1 (from torch<3.0.0,>=2.2.2->docling-ibm-models<3.0.0,>=2.0.6->docling)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.2.2->docling-ibm-models<3.0.0,>=2.0.6->docling) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (0.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->deepsearch-glm<0.27.0,>=0.26.1->docling) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.2.2->docling-ibm-models<3.0.0,>=2.0.6->docling) (3.0.2)\n",
            "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "Successfully installed sympy-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docling.document_converter import DocumentConverter"
      ],
      "metadata": {
        "id": "VoE5kMSWR9WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-TAkCrovhZw",
        "outputId": "530161ce-323c-4dc8-de17-c91c9d6f76bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier compressé 'scratch.zip' existe déjà. Aucun téléchargement nécessaire.\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python\n",
        "import os\n",
        "from pathlib import Path\n",
        "import csv\n",
        "import shutil\n",
        "\n",
        "from langchain.document_loaders import TextLoader\n",
        "from docling.document_converter import DocumentConverter\n",
        "# from google.colab import files\n",
        "\n",
        "class LoadingExtraction:\n",
        "    def __init__(self, chemin_acces, formats, output_dir):\n",
        "        self.chemin_acces = chemin_acces\n",
        "        self.formats = formats\n",
        "        self.output_dir = Path(output_dir)\n",
        "\n",
        "    def obtenir_chemins_acces(self, extensions=None):\n",
        "        return [\n",
        "            os.path.join(root, file)\n",
        "            for root, _, files in os.walk(self.chemin_acces)\n",
        "            for file in files\n",
        "            if not extensions or file.lower().endswith(tuple(extensions))\n",
        "        ]\n",
        "\n",
        "    def filtrer_par_format(self, chemins):\n",
        "        return {fmt: [path for path in chemins if path.lower().endswith(f\".{fmt}\")] for fmt in self.formats}\n",
        "\n",
        "    def charger_fichier_txt(self, chemins):\n",
        "        for path in chemins:\n",
        "            try:\n",
        "                with open(path, 'r', encoding='utf-8') as source_file:\n",
        "                    filename = os.path.basename(path)\n",
        "                    dest_path = self.output_dir / filename\n",
        "                    with open(dest_path, 'w', encoding='utf-8') as dest_file:\n",
        "                        dest_file.write(source_file.read())\n",
        "            except Exception as e:\n",
        "                print(f\"Erreur lors du traitement du fichier TXT {path}: {e}\")\n",
        "\n",
        "    def charger_fichier_csv(self, chemins):\n",
        "        for path in chemins:\n",
        "            try:\n",
        "                filename = os.path.basename(path).replace('.csv', '.txt')\n",
        "                dest_path = self.output_dir / filename\n",
        "                with open(path, 'r') as fichier_csv, open(dest_path, 'w') as fichier_txt:\n",
        "                    lecteur_csv = csv.reader(fichier_csv)\n",
        "                    for ligne in lecteur_csv:\n",
        "                        fichier_txt.write('\\t'.join(ligne) + '\\n')\n",
        "            except Exception as e:\n",
        "                print(f\"Erreur lors du traitement du fichier CSV {path}: {e}\")\n",
        "\n",
        "    def charger_fichier_pdf_html(self, chemins, format_type):\n",
        "        for path in chemins:\n",
        "            try:\n",
        "                filename = os.path.basename(path)\n",
        "                converter = DocumentConverter()\n",
        "                result = converter.convert(path)\n",
        "                dest_path = self.output_dir / f\"{filename}.md\"\n",
        "                with dest_path.open(\"w\", encoding=\"utf-8\") as fp:\n",
        "                    fp.write(result.document.export_to_markdown())\n",
        "            except Exception as e:\n",
        "                print(f\"Erreur lors du traitement du fichier {format_type.upper()} {path}: {e}\")\n",
        "\n",
        "    def ajouter_extension_txt(self):\n",
        "        for filename in self.output_dir.iterdir():\n",
        "            if filename.suffix == '.md':\n",
        "                new_filename = filename.with_suffix('.md.txt')\n",
        "                filename.rename(new_filename)\n",
        "                print(f\"Renommé: {filename} -> {new_filename}\")\n",
        "\n",
        "    def zipper_et_telecharger(self, zip_name=\"scratch\"):\n",
        "        zip_path = f\"{zip_name}.zip\"\n",
        "        if not os.path.exists(zip_path):  # Ne compresse et ne télécharge que si le fichier n'existe pas\n",
        "            shutil.make_archive(zip_name, 'zip', str(self.output_dir))\n",
        "            # files.download(zip_path)\n",
        "        else:\n",
        "            print(f\"Le fichier compressé '{zip_path}' existe déjà. Aucun téléchargement nécessaire.\")\n",
        "\n",
        "    def pipeline(self):\n",
        "        if self.output_dir.exists():\n",
        "            print(f\"Le répertoire '{self.output_dir}' existe déjà. Aucune action supplémentaire requise.\")\n",
        "            return\n",
        "\n",
        "        # Préparation\n",
        "        chemins = self.obtenir_chemins_acces()\n",
        "        fichiers_par_format = self.filtrer_par_format(chemins)\n",
        "\n",
        "        # Créer le dossier de sortie\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Charger les fichiers\n",
        "        self.charger_fichier_txt(fichiers_par_format.get('txt', []))\n",
        "        self.charger_fichier_csv(fichiers_par_format.get('csv', []))\n",
        "        self.charger_fichier_pdf_html(fichiers_par_format.get('pdf', []), \"pdf\")\n",
        "        self.charger_fichier_pdf_html(fichiers_par_format.get('html', []), \"html\")\n",
        "\n",
        "        # Ajouter extension .txt et compresser\n",
        "        self.ajouter_extension_txt()\n",
        "        self.zipper_et_telecharger()\n",
        "\n",
        "# Exécution\n",
        "if __name__ == \"__main__\":\n",
        "    chemin_acces = os.getcwd() + \"/data\"  # À remplacer\n",
        "    formats_supportés = [\"txt\", \"csv\", \"pdf\", \"html\"]\n",
        "    output_dir = \"scratch\"\n",
        "\n",
        "    loader = LoadingExtraction(chemin_acces, formats_supportés, output_dir)\n",
        "    loader.pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Déziper le fichier téléchargé\n",
        "!unzip scratch.zip -d scratch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyKJUZSKO_dz",
        "outputId": "2f55e4fb-374d-41e2-fbd8-007fdf8f6ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  scratch.zip\n",
            "  inflating: scratch/62_apres-avoir-valide-la-connexion-on-me-demande-a-nouveau-un-code-quel-est-ce-code-comment-f.txt  \n",
            "  inflating: scratch/70_quel-est-le-type-de-machine-adapte-a-mon-entreprise.txt  \n",
            "  inflating: scratch/80_quelles-ameliorations-contient-le-code-par-rapport-au-calcul-de-limpot.txt  \n",
            "  inflating: scratch/51_je-narrive-pas-a-saisir-mon-mot-de-passe-a-6-chiffres-comment-faire.txt  \n",
            "  inflating: scratch/3_pourquoi-la-hausse-des-prix-des-motos-depuis-lentree-en-vigueur-du-nouveau-code-general-de.txt  \n",
            "  inflating: scratch/22_que-dois-je-faire-pour-une-reconstitution-de-ma-carriere.txt  \n",
            "  inflating: scratch/43_comment-puis-je-payer-mes-impots-sur-e-services.txt  \n",
            "  inflating: scratch/19_je-nai-pas-recu-demail-pour-generer-mon-mot-de-passe-dois-je-refaire-une-nouvelle-demande-.txt  \n",
            "  inflating: scratch/15_que-faire-en-cas-de-difficultes-liees-a-lutilisation-quotidienne-de-la-mecef.txt  \n",
            "  inflating: scratch/26_comment-acceder-au-site-e-services.txt  \n",
            "  inflating: scratch/25_que-dois-je-faire-pour-beneficier-dune-affectation-pour-ordre.txt  \n",
            "  inflating: scratch/30_je-veux-postuler-a-un-concours-dentree-a-la-fonction-publique.txt  \n",
            "  inflating: scratch/76_en-quoi-consiste-laccomplissement-regulier-de-ses-obligations-fiscales.txt  \n",
            "  inflating: scratch/4_pourquoi-la-hausse-du-prix-de-lelectricite-depuis-lavenement-du-code-general-des-impots-no.txt  \n",
            "  inflating: scratch/5_concernant-la-telephonie-mobile-les-abonnes-ont-recu-un-sms-de-loperateur-les-informant-qu.txt  \n",
            "  inflating: scratch/14_je-suis-agent-de-letat-que-faire-pour-la-titularisation.txt  \n",
            "  inflating: scratch/33_y-a-t-il-un-risque-de-perdre-mes-documents-si-le-systeme-de-la-dgi-sarrete-de-fonctionner.txt  \n",
            "  inflating: scratch/code ge╠üne╠üral des impo╠éts.pdf.md.txt  \n",
            "  inflating: scratch/63_quelles-sont-les-innovations-concernant-lexercice-de-loption-pour-les-entreprises-relevant.txt  \n",
            "  inflating: scratch/10_quest-ce-que-laib.txt  \n",
            "  inflating: scratch/18_pourquoi-enregistrer-un-acte.txt  \n",
            "  inflating: scratch/9_les-comptes-des-nouveaux-utilisateurs-doivent-ils-etre-valides-par-la-dgi.txt  \n",
            "  inflating: scratch/2_a-quoi-dois-je-mattendre-apres-avoir-commis-une-faute-grave-en-tant-que-fonctionnaire-de-l.txt  \n",
            "  inflating: scratch/15_de-plus-la-loi-de-finances-de-2009-prevoit-des-exonerations-de-droits-de-douane-et-de-tva-.txt  \n",
            "  inflating: scratch/5_quelles-categories-dactes-a-enregistrer.txt  \n",
            "  inflating: scratch/2_comment-sexplique-la-hausse-des-prix-est-t-elle-liee-a-lapplication-de-nouvelles-taxes.txt  \n",
            "  inflating: scratch/75_le-prelevement-sur-les-cnf-est-il-un-impot.txt  \n",
            "  inflating: scratch/6_pourquoi-les-prelevements-varient-selon-les-communes-et-pourquoi-letat-insiste-pour-les-in.txt  \n",
            "  inflating: scratch/81_pourquoi-mon-historique-de-declarations-est-vide.txt  \n",
            "  inflating: scratch/48_qui-doit-payer-laib.txt  \n",
            "  inflating: scratch/18_quelles-sont-les-procedures-de-reclassement-dun-agent-de-letat.txt  \n",
            "  inflating: scratch/49_jai-valide-un-ordre-epayment-par-erreur-que-faire.txt  \n",
            "  inflating: scratch/27_que-dois-je-faire-pour-beneficier-de-letat-de-service-dun-agent-decede.txt  \n",
            "  inflating: scratch/44_quels-avantages-prevoit-le-code-general-des-impots-pour-les-nouvelles-entreprises.txt  \n",
            "  inflating: scratch/17_quelles-sont-les-pieces-a-fournir-pour-beneficier-dun-avancement-exceptionnel.txt  \n",
            "  inflating: scratch/21_jai-transmis-la-declaration-et-je-me-suis-trompe-comment-revenir-en-arriere.txt  \n",
            "  inflating: scratch/3_jai-perdu-mon-numero-e-services-comment-faire.txt  \n",
            "  inflating: scratch/13_il-est-propose-daccorder-un-abattement-de-taxe-aux-femmes-dans-un-contexte-social-pour-cor.txt  \n",
            "  inflating: scratch/16_quand-je-veux-ajouter-un-compte-bancaire-un-message-derreur-saffiche-que-faire.txt  \n",
            "  inflating: scratch/56_mon-code-de-connexion-a-usage-unique-ne-fonctionne-pas-comment-faire.txt  \n",
            "  inflating: scratch/6_je-suis-malade-que-dois-je-faire-je-veux-beneficier-dun-conge-maladie-je-veux-beneficier-d.txt  \n",
            "  inflating: scratch/7_quelle-est-la-procedure-de-demission-de-la-fonction-publique.txt  \n",
            "  inflating: scratch/68_dois-je-payer-ma-declaration-immediatement-apres-lavoir-declaree.txt  \n",
            "  inflating: scratch/6_jai-recu-le-mail-pour-definir-mon-mot-de-passe-que-dois-je-faire.txt  \n",
            "  inflating: scratch/35_y-a-t-il-des-entreprises-ou-des-secteurs-dactivite-qui-ne-sont-pas-concernes-par-la-reform.txt  \n",
            "  inflating: scratch/27_quelle-est-la-base-imposable-a-laib.txt  \n",
            "  inflating: scratch/42_jai-change-dadresse-email-comment-me-connecter-au-portail-e-services.txt  \n",
            "  inflating: scratch/60_dans-quel-delai-doit-on-payer-laib.txt  \n",
            "  inflating: scratch/17_jai-oublie-mon-mot-de-passe-comment-faire.txt  \n",
            "  inflating: scratch/19_que-dois-je-faire-pour-beneficier-dun-detachement.txt  \n",
            "  inflating: scratch/78_quest-ce-que-lautorisation-du-mandataire-social-demandee-a-ladhesion.txt  \n",
            "  inflating: scratch/61_quelles-sont-les-sanctions-encourues-pour-la-non-delivrance-des-factures-normalisees.txt  \n",
            "  inflating: scratch/0_comment-postuler-a-un-emploi-dans-la-fonction-publique.txt  \n",
            "  inflating: scratch/52_quelles-sont-les-regles-dimputation-de-laib.txt  \n",
            "  inflating: scratch/19_une-entreprise-specialisee-dans-la-construction-desirant-integrer-le-secteur-formel-quelle.txt  \n",
            "  inflating: scratch/14_monsieur-x-demande-si-sa-societe-creee-en-2022-doit-payer-la-patente-et-etre-soumise-a-lim.txt  \n",
            "  inflating: scratch/69_puis-je-modifier-mon-mot-de-passe.txt  \n",
            "  inflating: scratch/13_je-suis-eleve-fonctionnaire-que-dois-je-faire-pour-ma-promotion.txt  \n",
            "  inflating: scratch/Arre╠éte╠ü-fixant-les-re╠Çgles-applicables-aux-activite╠üs-de-communications-e╠ülectroniques-soumises-au-regime-de-lautorisation scanned.pdf.md.txt  \n",
            "  inflating: scratch/10_quel-est-le-delai-quun-agent-de-letat-doit-respecter-pour-formuler-un-recours.txt  \n",
            "  inflating: scratch/38_est-ce-normal-de-pouvoir-ajouter-librement-des-comptes-bancaires-sans-controle.txt  \n",
            "  inflating: scratch/0_pourquoi-le-code-general-des-impots-a-chage.txt  \n",
            "  inflating: scratch/4_je-pense-que-quelquun-essaye-ou-sest-connecte-a-mon-compte-e-services-comment-faire.txt  \n",
            "  inflating: scratch/31_comment-faut-il-payer-la-tps.txt  \n",
            "  inflating: scratch/5_a-quoi-dois-je-mattendre-apres-avoir-commis-une-faute-grave-en-tant-que-acdpe-collectivite.txt  \n",
            "  inflating: scratch/Status ASIN scanned.pdf.md.txt  \n",
            "  inflating: scratch/31_si-je-suis-admis-a-un-concours.txt  \n",
            "  inflating: scratch/12_a-qui-adresse-les-differents-recours.txt  \n",
            "  inflating: scratch/72_a-quoi-correspondent-les-differents-profils.txt  \n",
            "  inflating: scratch/29_je-veux-valider-mes-services-auxiliaires.txt  \n",
            "  inflating: scratch/Arcep - De╠ücret-fixant-les-conditions-de╠ütablissement-et-dexploitation-des-re╠üseaux-et-services-de-lIoT scanned.pdf.md.txt  \n",
            "  inflating: scratch/28_que-dois-je-faire-pour-beneficier-dune-evacuation-sanitaire.txt  \n",
            "  inflating: scratch/3_a-quoi-dois-je-mattendre-apres-avoir-commis-une-faute-grave-en-tant-que-acdpe.txt  \n",
            "  inflating: scratch/10_nous-sommes-submerges-de-taxes-il-y-a-trop-de-taxes.txt  \n",
            "  inflating: scratch/66_quest-ce-que-la-taxe-professionnelle-synthetique-tps.txt  \n",
            "  inflating: scratch/59_quelles-sont-les-sanctions-applicables-en-matiere-daib.txt  \n",
            "  inflating: scratch/12_en-ce-qui-concerne-la-delivrance-de-la-facture-normalisee-dans-certaines-pharmacies-il-arr.txt  \n",
            "  inflating: scratch/code des investissements scanned.pdf.md.txt  \n",
            "  inflating: scratch/21_quelles-sont-les-obligations-et-la-marche-a-suivre-pour-une-entreprise-individuelle-creee-.txt  \n",
            "  inflating: scratch/4_a-quoi-dois-je-mattendre-apres-avoir-commis-une-faute-grave-en-tant-que-ft.txt  \n",
            "  inflating: scratch/11_je-suis-eleve-fonctionnaire-que-dois-je-faire-pour-mon-engagement.txt  \n",
            "  inflating: scratch/code du nume╠ürique.pdf.md.txt  \n",
            "  inflating: scratch/26_que-dois-je-faire-pour-beneficier-dune-attestation-de-validite-de-service.txt  \n",
            "  inflating: scratch/41_qui-doit-signer-le-document-dautorisation-pour-ladhesion.txt  \n",
            "  inflating: scratch/Arcep - De╠ücret-conditions-identification-utilisateurs-services-communications-e╠ülectroniques scanned.pdf.md.txt  \n",
            "  inflating: scratch/22_les-informations-de-mon-entreprise-sont-erronees-sur-ma-fiche-contribuable-comment-procede.txt  \n",
            "  inflating: scratch/7_sur-ladministration-des-impots-nous-avons-remarque-labsence-de-seances-de-vulgarisation-du.txt  \n",
            "  inflating: scratch/chunks_overlap_novembre_2023.csv.txt  \n",
            "  inflating: scratch/2_combien-de-temps-les-documents-restent-disponibles-sur-le-portail.txt  \n",
            "  inflating: scratch/code du travail.pdf.md.txt  \n",
            "  inflating: scratch/17_est-ce-que-les-produits-qui-ont-ete-importes-avant-janvier-2022-sont-egalement-soumis-a-la.txt  \n",
            "  inflating: scratch/15_quelles-sont-les-pieces-a-fournir-pour-beneficier-dun-avancement.txt  \n",
            "  inflating: scratch/45_qui-sont-les-contribuables-soumis-a-ce-type-de-prelevement-fiscal.txt  \n",
            "  inflating: scratch/24_quelle-procedure-suivre-pour-enregistrer-un-acte.txt  \n",
            "  inflating: scratch/16_quelles-sont-les-pieces-a-fournir-pour-la-promotion-ou-avancement-de-grade.txt  \n",
            "  inflating: scratch/20_en-ce-qui-concerne-la-question-des-locataires-et-des-impots-il-ny-a-pas-de-reponse-claire-.txt  \n",
            "  inflating: scratch/1_a-qui-adresse-les-differents-recours.txt  \n",
            "  inflating: scratch/16_le-nouveau-code-general-des-impots-mentionne-la-tva-sur-les-produits-achetes-au-marche-dan.txt  \n",
            "  inflating: scratch/12_quelles-sont-les-conditions-a-remplir-pour-appartenir-au-fichier-des-contribuables.txt  \n",
            "  inflating: scratch/8_je-narrive-pas-a-passer-la-premiere-page-de-la-procedure-dadhesion-pourquoi.txt  \n",
            "  inflating: scratch/79_je-ne-suis-pas-eligible-quand-le-serai-je.txt  \n",
            "  inflating: scratch/53_impossible-de-valider-mon-formulaire-de-declaration-des-messages-derreurs-saffichent-pourq.txt  \n",
            "  inflating: scratch/8_pourquoi-la-reforme-considere-desormais-0-enfants-pour-tous-les-fonctionnaires-dans-le-cal.txt  \n",
            "  inflating: scratch/32_quels-sont-les-differents-regimes-dimposition-applicables-aux-nouvelles-entreprises.txt  \n",
            "  inflating: scratch/71_comment-acquerir-la-mecef-et-quelles-sont-les-demarches-a-suivre-pour-son-obtention.txt  \n",
            "  inflating: scratch/loi-n2020-26-du-29-septembre-2020-portant-code-des-marches-publique-au-benin-et-ses-decrets-dapplication.pdf.md.txt  \n",
            "  inflating: scratch/77_quel-est-le-taux-du-prelevement-sur-les-contribuables-non-connus-du-fisc.txt  \n",
            "  inflating: scratch/Portail National des services publics du Be╠ünin.html.md.txt  \n",
            "  inflating: scratch/9_pourquoi-le-peuple-na-pas-ete-informe-de-la-reintroduction-de-la-tva-sur-les-motos-et-sil-.txt  \n",
            "  inflating: scratch/11_est-ce-que-nous-depensons-plus-que-les-autres-pays-pour-les-axes.txt  \n",
            "  inflating: scratch/74_il-mest-impossible-de-passer-la-page-des-conditions-dutilisation-que-faire.txt  \n",
            "  inflating: scratch/36_je-ne-retrouve-pas-mes-anciennes-declarations-deposees-en-centre-est-ce-normal.txt  \n",
            "  inflating: scratch/28_la-dgi-a-t-elle-agree-des-editeurs-de-logiciels-ou-fournit-elle-des-logiciels-de-comptabil.txt  \n",
            "  inflating: scratch/30_comment-faire-pour-joindre-un-document-annexe-a-la-declaration.txt  \n",
            "  inflating: scratch/21_que-dois-je-faire-pour-un-changement-de-corps.txt  \n",
            "  inflating: scratch/25_jai-recu-un-courrier-avec-un-numero-e-services-quest-ce-que-cest.txt  \n",
            "  inflating: scratch/37_je-souhaite-enregistrer-mon-compte-mais-ma-banque-nest-pas-dans-la-liste-que-faire.txt  \n",
            "  inflating: scratch/0_je-suis-alle-au-bout-du-processus-dadhesion-mais-je-nai-pas-recu-demail.txt  \n",
            "  inflating: scratch/50_lenregistrement-dun-acte-est-il-toujours-payant-et-combien-coute-t-il.txt  \n",
            "  inflating: scratch/23_lorsque-je-renseigne-le-code-recu-par-sms-pour-lobtention-de-mon-ifu-un-message-derreur-sa.txt  \n",
            "  inflating: scratch/46_pourquoi-avoir-instaure-ce-prelevement-fiscal.txt  \n",
            "  inflating: scratch/14_comment-calculer-laib.txt  \n",
            "  inflating: scratch/82_ou-se-rendre-pour-enregistrer-un-acte.txt  \n",
            "  inflating: scratch/code pe╠ünal.pdf.md.txt  \n",
            "  inflating: scratch/64_jai-commence-une-declaration-mais-nai-pas-le-temps-de-la-terminer-puis-je-lenregistrer.txt  \n",
            "  inflating: scratch/58_quelles-sont-les-operations-ou-biens-exoneres-de-laib.txt  \n",
            "  inflating: scratch/57_est-il-obligatoire-denregistrer-un-acte.txt  \n",
            "  inflating: scratch/13_les-machines-electroniques-certifiees-de-facturation-peuvent-elles-fonctionner-avec-le-log.txt  \n",
            "  inflating: scratch/7_jai-termine-ma-declaration-mais-elle-ne-saffiche-pas-dans-lhistorique.txt  \n",
            "  inflating: scratch/20_que-dois-je-faire-pour-une-mise-en-disponibilite.txt  \n",
            "  inflating: scratch/73_pourquoi-je-nai-pas-recu-de-numero-e-services.txt  \n",
            "  inflating: scratch/23_que-dois-je-faire-pour-un-rectificatif.txt  \n",
            "  inflating: scratch/18_concernant-les-impots-sur-les-proprietes-ils-ont-remarque-que-lavis-dimposition-quils-ont-.txt  \n",
            "  inflating: scratch/9_a-lissue-de-la-decision-du-juge-administratif-en-ta-faveur-que-faire-pour-reprendre-servic.txt  \n",
            "  inflating: scratch/11_quel-est-le-champ-dapplication-de-laib.txt  \n",
            "  inflating: scratch/54_que-dois-je-faire-pour-pouvoir-utiliser-le-telepaiement-par-epayment.txt  \n",
            "  inflating: scratch/1_payons-nous-trop-dimpots-au-benin-par-rapport-aux-autres-pays-de-lunion-europeenne.txt  \n",
            "  inflating: scratch/47_jai-un-credit-de-tva-pour-lequel-je-souhaite-demander-le-remboursement-puis-je-le-faire-en.txt  \n",
            "  inflating: scratch/55_dois-je-transmettre-en-parallele-mon-formulaire-de-declaration-papier-a-la-dgi.txt  \n",
            "  inflating: scratch/Portail National des services publics du Be╠ünin.md.txt  \n",
            "  inflating: scratch/ASIN.txt        \n",
            "  inflating: scratch/67_jai-recu-mon-email-de-confirmation-quand-vais-je-pouvoir-me-connecter.txt  \n",
            "  inflating: scratch/24_que-dois-je-faire-pour-beneficier-dindemnite-de-specialisation.txt  \n",
            "  inflating: scratch/40_quelles-sont-les-facilites-fiscales-accordees-aux-nouvelles-entreprises.txt  \n",
            "  inflating: scratch/39_que-signifie-le-sigle-cnf.txt  \n",
            "  inflating: scratch/29_je-narrive-pas-a-inserer-des-pieces-jointes-quel-est-le-probleme.txt  \n",
            "  inflating: scratch/8_en-cas-de-retour-dexil-en-tant-quagent-de-letat-quelle-procedure-menee-pour-reprendre-serv.txt  \n",
            "  inflating: scratch/passeport.txt   \n",
            "  inflating: scratch/1_peut-on-normaliser-une-facture-davoir-etablie-sur-une-facture-anterieure-a-la-mise-en-plac.txt  \n",
            "  inflating: scratch/20_ma-demande-dadhesion-a-ete-rejetee-pourquoi.txt  \n",
            "  inflating: scratch/34_quelles-sont-les-personnes-imposables-a-la-tps.txt  \n",
            "  inflating: scratch/65_tous-les-impots-auxquels-je-suis-assujetti-ne-saffichent-pas-sur-mon-tableau-de-bord-comme.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DocumentProcessor:\n",
        "    def __init__(self, chunk_size=768, chunk_overlap=50):\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_overlap = chunk_overlap\n",
        "\n",
        "    def split_text(self, text):\n",
        "     #Découper le texte en chunks\n",
        "        chunks = []\n",
        "        start = 0\n",
        "        while start < len(text):\n",
        "            end = min(start + self.chunk_size, len(text))\n",
        "            chunks.append(text[start:end])\n",
        "            start += self.chunk_size - self.chunk_overlap  # Décalage avec chevauchement\n",
        "        return chunks\n",
        "\n",
        "    def process_file(self, file_path):\n",
        "        \"\"\"\n",
        "        Lit un fichier, le découpe en chunks, et ajoute des métadonnées.\n",
        "        \"\"\"\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "\n",
        "        # Créer des métadonnées\n",
        "        metadata = {\n",
        "            \"document_name\": os.path.basename(file_path),\n",
        "            \"path\": file_path,\n",
        "            \"source_type\": \"txt\"\n",
        "        }\n",
        "\n",
        "        # Découper le texte et associer les métadonnées\n",
        "        chunks = self.split_text(text)\n",
        "        processed_chunks = [{\"content\": chunk, \"metadata\": metadata} for chunk in chunks]\n",
        "\n",
        "        return processed_chunks\n",
        "\n",
        "    def process_folder(self, folder_path):\n",
        "        \"\"\"\n",
        "        Parcourt un dossier, traite chaque fichier .txt, et renvoie une liste de chunks.\n",
        "        \"\"\"\n",
        "        all_chunks = []\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith(\".txt\"):\n",
        "                file_path = os.path.join(folder_path, filename)\n",
        "                chunks = self.process_file(file_path)\n",
        "                all_chunks.extend(chunks)  # Ajouter tous les chunks à la liste globale\n",
        "        return all_chunks\n",
        "\n",
        "\n",
        "# Exemple d'utilisation\n",
        "if __name__ == \"__main__\":\n",
        "    folder_path = \"/content/scratch\"\n",
        "    processor = DocumentProcessor()\n",
        "\n",
        "    # Traiter tous les fichiers dans le dossier\n",
        "    chunks = processor.process_folder(folder_path)"
      ],
      "metadata": {
        "id": "K_xFw_EDvpBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "class DocumentProcessor:\n",
        "    def __init__(self, model_name=\"camembert-base\", chunk_size=512, chunk_overlap=50):\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_overlap = chunk_overlap\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    def split_text_by_tokens(self, text):\n",
        "        tokens = self.tokenizer(text, return_tensors=\"pt\", truncation=False)[\"input_ids\"][0]\n",
        "        chunks = []\n",
        "\n",
        "        start = 0\n",
        "        while start < len(tokens):\n",
        "            end = min(start + self.chunk_size, len(tokens))\n",
        "            chunk_tokens = tokens[start:end]\n",
        "            chunks.append(self.tokenizer.decode(chunk_tokens))\n",
        "            start += self.chunk_size - self.chunk_overlap\n",
        "\n",
        "        return chunks\n"
      ],
      "metadata": {
        "id": "L-Yn8Vglx0DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-vgHyOfff8L",
        "outputId": "ed3592b0-55c4-4c92-bb4c-ed217669d0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6769"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuLYb14sYcHy",
        "outputId": "91b04fac-4982-49c5-a4d7-9bc7f8423c1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FnGXQM8oYg-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, using CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp8eXiUPv7yR",
        "outputId": "8ab629b3-4718-4347-8a72-a30120d4f1a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('dangvantuan/french-document-embedding', trust_remote_code=True, device=device)\n",
        "embeddings = []\n",
        "for chunk in chunks:\n",
        "  sentences = chunk['content']\n",
        "  embedding = model.encode(sentences,device=device) # Use GPU for encoding)\n",
        "  embeddings.append(embedding)"
      ],
      "metadata": {
        "id": "oOTWgJ8jwC04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwBbLo6IZjPu",
        "outputId": "3d65a39f-6fa0-4af6-d88d-84e3766e5eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6769"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x045eN-sZzcF",
        "outputId": "7dbfc3ad-b005-4ad0-c8d8-843592e6d38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir les embeddings en NumPy float32 pour FAISS\n",
        "import numpy as np\n",
        "embeddings = np.array(embeddings, dtype=\"float32\")\n",
        "\n",
        "import faiss\n",
        "\n",
        "# Définir la dimension des vecteurs\n",
        "dimension = embeddings.shape[1]\n",
        "\n",
        "# Créer un index FAISS avec distance L2\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# Ajouter les embeddings dans l'index\n",
        "index.add(embeddings)\n",
        "\n",
        "# Exemple de métadonnées associées à chaque chunk\n",
        "metadata = [{\"id\": i, \"content\": chunk['content'], \"metadata\": chunk[\"metadata\"]} for i, chunk in enumerate(chunks)]\n",
        "\n",
        "# Sauvegarder les métadonnées parallèlement\n",
        "metadata_store = {i: meta for i, meta in enumerate(metadata)}\n",
        "\n",
        "print(f\"Nombre total de vecteurs dans l'index : {index.ntotal}\")\n",
        "\n",
        "# Associer les indices aux chunks\n",
        "id_to_chunk = {i: chunk for i, chunk in enumerate(chunks)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ7JvyLmwJLb",
        "outputId": "5d23a4cf-cec1-4a01-8df5-9bf65c5f8484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre total de vecteurs dans l'index : 6769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "vector_store = FAISS(\n",
        "    embedding_function=None,\n",
        "    index=index,\n",
        "    docstore=chunks,\n",
        "    index_to_docstore_id=id_to_chunk\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Grw03vYHwe5H",
        "outputId": "4f5d160e-8530-4cbb-ce93-a8b0c7736db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Effectuer une recherche\n",
        "\n",
        "query_vector = \"quels sont les documents à fournir pour l'acte de naissance\"\n",
        "\n",
        "# Convert the query to an embedding using the SentenceTransformer model\n",
        "query_embedding = model.encode(query_vector)\n",
        "\n",
        "# Reshape to a 2D array with a single row\n",
        "query_embedding = query_embedding.reshape(1, -1).astype(\"float32\")\n",
        "\n",
        "# Use query_embedding instead of query_vector for search\n",
        "distances, indices = index.search(query_embedding, 5)  # Trouver le plus proche\n",
        "\n",
        "# Instead of accessing docstore using id_to_chunk, directly use the indices\n",
        "results = [vector_store.docstore[idx] for idx in indices[0]]\n",
        "# id_to_chunk is not needed here as indices already point to the correct documents in docstore# Get the index of the closest chunk\n",
        "\n",
        "#closest_chunk_index = indices[0][0]\n",
        "\n",
        "# Access the metadata using the index from metadata_store\n",
        "#result = metadata_store[closest_chunk_index]"
      ],
      "metadata": {
        "id": "P9DuLSDiwgOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher les résultats\n",
        "print(f\"Résultats :\")  # Changed to \"Résultats\" as there can be multiple\n",
        "for i, result in enumerate(results):\n",
        "    print(f\"Résultat {i + 1}:\")\n",
        "    print(f\"ID : {metadata_store[indices[0][i]]['id']}\")  # Access metadata using metadata_store and indices\n",
        "    print(f\"Contenu : {result['content']}\")\n",
        "    print(f\"Metadata : {metadata_store[indices[0][i]]['metadata']}\")  # Access metadata using metadata_store and indices\n",
        "    print(f\"Distance : {distances[0][i]} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD1Z_kpTdvZp",
        "outputId": "c94ed9d4-f0d1-485c-bab1-46bf5eacd91e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résultats :\n",
            "Résultat 1:\n",
            "ID : 3348\n",
            "Contenu :  actes d’état civil. Elle permet d’inscrire le nouveau-né sur les registres de l’état civil, ce qui fait officiellement de lui un citoyen béninois. La déclaration de naissance est obligatoire. Elle permet d'établir l'acte de naissance. En effet, tout parent, père ou mère a l’obligation de déclarer dans un délai maximum de 21 jours, la naissance de son enfant (Article 34 de la loi 2015 du 08 décembre 2015 portant code de l’enfant en République du Bénin). Si le délai arrive à expiration un jour férié, la déclaration sera reçue valablement le premier jour ouvrable suivant. En pays étranger, les déclarations aux agents diplomatiques ou aux Consuls sont faites dans le même délai et dans les mêmes conditions. Durée estimée: 72 heures. Coût de service: gratuit. Dém\n",
            "Metadata : {'document_name': 'chunks_overlap_novembre_2023.csv.txt', 'path': '/content/scratch/chunks_overlap_novembre_2023.csv.txt', 'source_type': 'txt'}\n",
            "Distance : 0.3436068296432495 \n",
            "\n",
            "Résultat 2:\n",
            "ID : 4534\n",
            "Contenu : s enfants. Acte de mariage (facultatif). Une photo d’identité de l’époux ou de la mère célibataire. Déclaration sur l’honneur de la mère célibataire. Certificat de vie et de charge pour les enfants. Certificat de scolarité pour les enfants de plus de 6 ans. Exemplaire ou copie du contrat d’apprentissage. Certificat Médical pour les enfants maladifs. Déclaration de grossesse\thttps://service-public.bj/public/services/service/PS00616\tMinistère du Travail et de la Fonction Publique\tservice, travail, institution, demande, fonction, publique, charge, acte, ministere, faire\n",
            "Catégorie: Ministère du Travail et de la Fonction Publique.\n",
            "Titre: Délivrance d’attestation d’immatriculation et de paiement des cotisations au travailleur.\n",
            "Délivrance d’attestation d’immatricul\n",
            "Metadata : {'document_name': 'chunks_overlap_novembre_2023.csv.txt', 'path': '/content/scratch/chunks_overlap_novembre_2023.csv.txt', 'source_type': 'txt'}\n",
            "Distance : 0.36607539653778076 \n",
            "\n",
            "Résultat 3:\n",
            "ID : 2977\n",
            "Contenu : ossier de demande d'établissement de la carte nationale d'identité et du passeport en République du Bénin. La seule déclaration de la situation matrimoniale fait foi.. 1- Etablissement. Copie légalisée de l’extrait d’acte de naissance + sa Souche (Volet n°3) ou le PV pour les jugements supplétifs ou d’autorisation ; certificat de possession d’Etat ; certificat de résidence ; preuve de profession ; acte de naturalisation pour les étrangers naturalisés béninois ; copie légalisée de deux témoins ; autorisation parentale pour les mineurs ; quatre photos d’identité à fond blanc ; certificat médical de port de verres pour les personnes portant des verres.. 2-Renouvellement. ancienne carte Nationale d'identité. Copie légalisée de l’extrait d’acte de naissance + sa \n",
            "Metadata : {'document_name': 'chunks_overlap_novembre_2023.csv.txt', 'path': '/content/scratch/chunks_overlap_novembre_2023.csv.txt', 'source_type': 'txt'}\n",
            "Distance : 0.3673810064792633 \n",
            "\n",
            "Résultat 4:\n",
            "ID : 1747\n",
            "Contenu : context\tlinks\tcategory\ttopics\n",
            "Catégorie: Agence Nationale d’Identification des Personnes.\n",
            "Titre: Délivrance d'acte de naissance sécurisé (Part 1).\n",
            "Délivrance d'acte de naissance sécurisé.  Acte de naissance PRAN/PEDEC  Acte de naissance copie intégrale  Acte de naissance par transcription. Durée estimée: 48h. Coût de service: 1000 FCFA. Site Internet: https://eservices.anip.bj. Qui peut faire la demande? Tout citoyen de nationalité béninoise. Institution en charge du service: Agence Nationale d’Identification des Personnes\thttps://service-public.bj/public/services/service/PS00393\tAgence Nationale d’Identification des Personnes\tservice, identification, personnes, acte, nationale, copie, naissance, cotonou, agence, institution\n",
            "Catégorie: Agence Nationale d’Ide\n",
            "Metadata : {'document_name': 'chunks_overlap_novembre_2023.csv.txt', 'path': '/content/scratch/chunks_overlap_novembre_2023.csv.txt', 'source_type': 'txt'}\n",
            "Distance : 0.3750821650028229 \n",
            "\n",
            "Résultat 5:\n",
            "ID : 3019\n",
            "Contenu : alisée de l’acte de mariage,. Une photocopie légalisée de la souche de l’acte de mariage. Une somme de quarante-cinq mille (45000) francs CFA.. NB : Transcription des mariages célébrés à l’étranger.. DEMANDE DE NATURALISATION : Une demande manuscrite adressée au Garde des Sceaux ; Un extrait d’acte de naissance du postulant (en 3 exemplaires); Une attestation de résidence mentionnant que le requérant réside sur le territoire national depuis au moins trois (03) ans; Une photocopie légalisée du passeport ou de la carte d’identité du postulant ; Un certificat de visite et contre visite ; Un certificat de travail ou toutes autres pièces en tenant lieu ou un registre de commerce pour le requérant commerçant ; Un certificat de nationalité du pays d’origine ou tout\n",
            "Metadata : {'document_name': 'chunks_overlap_novembre_2023.csv.txt', 'path': '/content/scratch/chunks_overlap_novembre_2023.csv.txt', 'source_type': 'txt'}\n",
            "Distance : 0.3820019066333771 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# La Recherche"
      ],
      "metadata": {
        "id": "_TKBCUmE4HDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Bo4msPn--9cP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt"
      ],
      "metadata": {
        "id": "XSZ7IKto-4Js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM"
      ],
      "metadata": {
        "id": "qL1u0anS-UBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, using CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E3bInywGuZc",
        "outputId": "817c4ebb-95cf-4e19-ea66-89901fe94171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "\n",
        "# Quantize the model to 4-bit to reduce memory footprint\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=\"auto\",\n",
        "    # Use quantization and offload to CPU if necessary\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    offload_folder=\"offload\", # Specify a folder for offloading\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# ... rest of your code ...\n",
        "\n",
        "prompt = \"Give me a short introduction to large language model.\"\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=512\n",
        ")\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "Y1ONW3GqiCSx",
        "outputId": "7c546e6a-85d0-4fd4-90ac-42b53c954689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-a323d5aa07bc>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3657\u001b[0;31m             hf_quantizer.validate_environment(\n\u001b[0m\u001b[1;32m   3658\u001b[0m                 \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_flax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_flax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3659\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m             )\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_bitsandbytes_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0;34m\"Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             )\n",
            "\u001b[0;31mImportError\u001b[0m: Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U3ERgUel3va",
        "outputId": "d08babbb-b789-4882-83e5-aa1795cc5919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "\n",
        "# Quantize the model to 4-bit to reduce memory footprint\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=\"auto\",\n",
        "    # Use quantization and offload to CPU if necessary\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    offload_folder=\"offload\", # Specify a folder for offloading\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# ... rest of your code ..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "htzXYaEulu-C",
        "outputId": "8dbf721a-5d29-4aab-a481-f26f96251d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-41499450e072>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3657\u001b[0;31m             hf_quantizer.validate_environment(\n\u001b[0m\u001b[1;32m   3658\u001b[0m                 \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_flax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_flax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3659\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m             )\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_bitsandbytes_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0;34m\"Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             )\n",
            "\u001b[0;31mImportError\u001b[0m: Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}